{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c30093a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T08:14:54.680031Z",
     "iopub.status.busy": "2025-04-11T08:14:54.679746Z",
     "iopub.status.idle": "2025-04-11T08:14:59.437168Z",
     "shell.execute_reply": "2025-04-11T08:14:59.436135Z"
    },
    "papermill": {
     "duration": 4.764209,
     "end_time": "2025-04-11T08:14:59.439472",
     "exception": false,
     "start_time": "2025-04-11T08:14:54.675263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.4)\r\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f4fa9c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T08:14:59.447533Z",
     "iopub.status.busy": "2025-04-11T08:14:59.446857Z",
     "iopub.status.idle": "2025-04-11T08:15:03.047071Z",
     "shell.execute_reply": "2025-04-11T08:15:03.046076Z"
    },
    "papermill": {
     "duration": 3.605838,
     "end_time": "2025-04-11T08:15:03.048806",
     "exception": false,
     "start_time": "2025-04-11T08:14:59.442968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting findspark\r\n",
      "  Downloading findspark-2.0.1-py2.py3-none-any.whl.metadata (352 bytes)\r\n",
      "Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\r\n",
      "Installing collected packages: findspark\r\n",
      "Successfully installed findspark-2.0.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c6d2e71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T08:15:03.056516Z",
     "iopub.status.busy": "2025-04-11T08:15:03.056209Z",
     "iopub.status.idle": "2025-04-11T08:15:06.534155Z",
     "shell.execute_reply": "2025-04-11T08:15:06.533258Z"
    },
    "papermill": {
     "duration": 3.484437,
     "end_time": "2025-04-11T08:15:06.536410",
     "exception": false,
     "start_time": "2025-04-11T08:15:03.051973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\r\n",
      "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2.4.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas) (2024.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dddfa9f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T08:15:06.544501Z",
     "iopub.status.busy": "2025-04-11T08:15:06.544161Z",
     "iopub.status.idle": "2025-04-11T08:15:16.038738Z",
     "shell.execute_reply": "2025-04-11T08:15:16.037654Z"
    },
    "papermill": {
     "duration": 9.500838,
     "end_time": "2025-04-11T08:15:16.040584",
     "exception": false,
     "start_time": "2025-04-11T08:15:06.539746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/11 08:15:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession is active and ready to use.\n"
     ]
    }
   ],
   "source": [
    "import findspark  # This helps us find and use Apache Spark\n",
    "findspark.init()  # Initialize findspark to locate Spark\n",
    "from pyspark.sql import SparkSession  \n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, LongType, DateType\n",
    "import pandas as pd  \n",
    "# Initialize a Spark Session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"COVID-19 Data Analysis\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Check if the Spark Session is active\n",
    "if 'spark' in locals() and isinstance(spark, SparkSession):\n",
    "    print(\"SparkSession is active and ready to use.\")\n",
    "else:\n",
    "    print(\"SparkSession is not active. Please create a SparkSession.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24c5fdb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T08:15:16.052755Z",
     "iopub.status.busy": "2025-04-11T08:15:16.051547Z",
     "iopub.status.idle": "2025-04-11T08:15:16.834764Z",
     "shell.execute_reply": "2025-04-11T08:15:16.834079Z"
    },
    "papermill": {
     "duration": 0.790355,
     "end_time": "2025-04-11T08:15:16.836355",
     "exception": false,
     "start_time": "2025-04-11T08:15:16.046000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vaccination_data = pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/KpHDlIzdtR63BdTofl1mOg/owid-covid-latest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "700f9906",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T08:15:16.844558Z",
     "iopub.status.busy": "2025-04-11T08:15:16.843848Z",
     "iopub.status.idle": "2025-04-11T08:15:16.869616Z",
     "shell.execute_reply": "2025-04-11T08:15:16.868538Z"
    },
    "papermill": {
     "duration": 0.031209,
     "end_time": "2025-04-11T08:15:16.871061",
     "exception": false,
     "start_time": "2025-04-11T08:15:16.839852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying the first 5 records of the vaccination data:\n",
      "  continent  total_cases  total_deaths  total_vaccinations    population\n",
      "0      Asia     235214.0        7998.0                 NaN  4.112877e+07\n",
      "1       NaN   13145380.0      259117.0                 NaN  1.426737e+09\n",
      "2    Europe     335047.0        3605.0                 NaN  2.842318e+06\n",
      "3    Africa     272139.0        6881.0                 NaN  4.490323e+07\n",
      "4   Oceania       8359.0          34.0                 NaN  4.429500e+04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    }
   ],
   "source": [
    "print(\"Displaying the first 5 records of the vaccination data:\")\n",
    "columns_to_display = ['continent', 'total_cases', 'total_deaths', 'total_vaccinations', 'population']\n",
    "# Show the first 5 records\n",
    "print(vaccination_data[columns_to_display].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2fa92ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T08:15:16.880237Z",
     "iopub.status.busy": "2025-04-11T08:15:16.879442Z",
     "iopub.status.idle": "2025-04-11T08:15:23.004394Z",
     "shell.execute_reply": "2025-04-11T08:15:23.002952Z"
    },
    "papermill": {
     "duration": 6.132003,
     "end_time": "2025-04-11T08:15:23.006711",
     "exception": false,
     "start_time": "2025-04-11T08:15:16.874708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+------------+------------------+----------+\n",
      "|    continent|total_cases|total_deaths|total_vaccinations|population|\n",
      "+-------------+-----------+------------+------------------+----------+\n",
      "|         Asia|     235214|        7998|                 0|  41128772|\n",
      "|          nan|   13145380|      259117|                 0|1426736614|\n",
      "|       Europe|     335047|        3605|                 0|   2842318|\n",
      "|       Africa|     272139|        6881|                 0|  44903228|\n",
      "|      Oceania|       8359|          34|                 0|     44295|\n",
      "|       Europe|      48015|         159|                 0|     79843|\n",
      "|       Africa|     107481|        1937|                 0|  35588996|\n",
      "|North America|       3904|          12|                 0|     15877|\n",
      "|North America|       9106|         146|                 0|     93772|\n",
      "|South America|   10101218|      130663|                 0|  45510324|\n",
      "|         Asia|     452273|        8777|                 0|   2780472|\n",
      "|North America|      44224|         292|                 0|    106459|\n",
      "|          nan|  301499099|     1637249|        9104304615|4721383370|\n",
      "|      Oceania|   11861161|       25236|                 0|  26177410|\n",
      "|       Europe|    6082444|       22534|                 0|   8939617|\n",
      "|         Asia|     835757|       10353|                 0|  10358078|\n",
      "|North America|      39127|         849|                 0|    409989|\n",
      "|         Asia|     696614|        1536|                 0|   1472237|\n",
      "|         Asia|    2051348|       29499|                 0| 171186368|\n",
      "|North America|     108582|         593|                 0|    281646|\n",
      "+-------------+-----------+------------+------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert to Spark DataFrame directly\n",
    "# Define the schema\n",
    "schema = StructType([\n",
    "    StructField(\"continent\", StringType(), True),\n",
    "    StructField(\"total_cases\", LongType(), True),\n",
    "    StructField(\"total_deaths\", LongType(), True),\n",
    "    StructField(\"total_vaccinations\", LongType(), True),\n",
    "    StructField(\"population\", LongType(), True)\n",
    "])\n",
    "\n",
    "# Convert the columns to the appropriate data types\n",
    "vaccination_data['continent'] = vaccination_data['continent'].astype(str)  # Ensures continent is a string\n",
    "vaccination_data['total_cases'] = vaccination_data['total_cases'].fillna(0).astype('int64')  # Fill NaNs and convert to int\n",
    "vaccination_data['total_deaths'] = vaccination_data['total_deaths'].fillna(0).astype('int64')  # Fill NaNs and convert to int\n",
    "vaccination_data['total_vaccinations'] = vaccination_data['total_vaccinations'].fillna(0).astype('int64')  # Fill NaNs and convert to int\n",
    "vaccination_data['population'] = vaccination_data['population'].fillna(0).astype('int64')  # Fill NaNs and convert to int\n",
    "\n",
    "spark_df = spark.createDataFrame(vaccination_data[schema.fieldNames()])  # Use only the specified fields\n",
    "# Show the Spark DataFrame\n",
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1ec5f64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T08:15:23.018782Z",
     "iopub.status.busy": "2025-04-11T08:15:23.017892Z",
     "iopub.status.idle": "2025-04-11T08:15:23.027327Z",
     "shell.execute_reply": "2025-04-11T08:15:23.026375Z"
    },
    "papermill": {
     "duration": 0.015904,
     "end_time": "2025-04-11T08:15:23.029087",
     "exception": false,
     "start_time": "2025-04-11T08:15:23.013183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema of the Spark DataFrame:\n",
      "root\n",
      " |-- continent: string (nullable = true)\n",
      " |-- total_cases: long (nullable = true)\n",
      " |-- total_deaths: long (nullable = true)\n",
      " |-- total_vaccinations: long (nullable = true)\n",
      " |-- population: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Schema of the Spark DataFrame:\")\n",
    "spark_df.printSchema()\n",
    "# Print the structure of the DataFrame (columns and types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e8d513c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T08:15:23.043207Z",
     "iopub.status.busy": "2025-04-11T08:15:23.042902Z",
     "iopub.status.idle": "2025-04-11T08:15:23.231881Z",
     "shell.execute_reply": "2025-04-11T08:15:23.230951Z"
    },
    "papermill": {
     "duration": 0.197469,
     "end_time": "2025-04-11T08:15:23.233232",
     "exception": false,
     "start_time": "2025-04-11T08:15:23.035763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+------------+------------------+----------+\n",
      "|continent|total_cases|total_deaths|total_vaccinations|population|\n",
      "+---------+-----------+------------+------------------+----------+\n",
      "|     Asia|     235214|        7998|                 0|  41128772|\n",
      "|      nan|   13145380|      259117|                 0|1426736614|\n",
      "|   Europe|     335047|        3605|                 0|   2842318|\n",
      "|   Africa|     272139|        6881|                 0|  44903228|\n",
      "|  Oceania|       8359|          34|                 0|     44295|\n",
      "+---------+-----------+------------+------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List the names of the columns you want to display\n",
    "columns_to_display = ['continent', 'total_cases', 'total_deaths', 'total_vaccinations', 'population']\n",
    "# Display the first 5 records of the specified columns\n",
    "spark_df.select(columns_to_display).show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcf4e781",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T08:15:23.242268Z",
     "iopub.status.busy": "2025-04-11T08:15:23.241792Z",
     "iopub.status.idle": "2025-04-11T08:15:23.347831Z",
     "shell.execute_reply": "2025-04-11T08:15:23.346624Z"
    },
    "papermill": {
     "duration": 0.112096,
     "end_time": "2025-04-11T08:15:23.349323",
     "exception": false,
     "start_time": "2025-04-11T08:15:23.237227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying the 'continent' and 'total_cases' columns:\n",
      "+---------+-----------+\n",
      "|continent|total_cases|\n",
      "+---------+-----------+\n",
      "|     Asia|     235214|\n",
      "|      nan|   13145380|\n",
      "|   Europe|     335047|\n",
      "|   Africa|     272139|\n",
      "|  Oceania|       8359|\n",
      "+---------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Displaying the 'continent' and 'total_cases' columns:\")\n",
    "# Show only the 'continent' and 'total_cases' columns\n",
    "spark_df.select('continent', 'total_cases').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43eddc0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T08:15:23.358869Z",
     "iopub.status.busy": "2025-04-11T08:15:23.358468Z",
     "iopub.status.idle": "2025-04-11T08:15:23.489300Z",
     "shell.execute_reply": "2025-04-11T08:15:23.488466Z"
    },
    "papermill": {
     "duration": 0.13757,
     "end_time": "2025-04-11T08:15:23.491043",
     "exception": false,
     "start_time": "2025-04-11T08:15:23.353473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering records where 'total_cases' is greater than 1,000,000:\n",
      "+-------------+-----------+------------+------------------+----------+\n",
      "|    continent|total_cases|total_deaths|total_vaccinations|population|\n",
      "+-------------+-----------+------------+------------------+----------+\n",
      "|          nan|   13145380|      259117|                 0|1426736614|\n",
      "|South America|   10101218|      130663|                 0|  45510324|\n",
      "|          nan|  301499099|     1637249|        9104304615|4721383370|\n",
      "|      Oceania|   11861161|       25236|                 0|  26177410|\n",
      "|       Europe|    6082444|       22534|                 0|   8939617|\n",
      "+-------------+-----------+------------+------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Filtering records where 'total_cases' is greater than 1,000,000:\")\n",
    " # Show records with more than 1 million total cases\n",
    "spark_df.filter(spark_df['total_cases'] > 1000000).show(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d384b56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T08:15:23.500719Z",
     "iopub.status.busy": "2025-04-11T08:15:23.500400Z",
     "iopub.status.idle": "2025-04-11T08:15:23.724947Z",
     "shell.execute_reply": "2025-04-11T08:15:23.724146Z"
    },
    "papermill": {
     "duration": 0.231438,
     "end_time": "2025-04-11T08:15:23.726890",
     "exception": false,
     "start_time": "2025-04-11T08:15:23.495452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+----------------+---------+------------------+-----------+\n",
      "|total_deaths|population|death_percentage|continent|total_vaccinations|total_cases|\n",
      "+------------+----------+----------------+---------+------------------+-----------+\n",
      "|        7998|  41128772|           0.02%|     Asia|                 0|     235214|\n",
      "|      259117|1426736614|           0.02%|      nan|                 0|   13145380|\n",
      "|        3605|   2842318|           0.13%|   Europe|                 0|     335047|\n",
      "|        6881|  44903228|           0.02%|   Africa|                 0|     272139|\n",
      "|          34|     44295|           0.08%|  Oceania|                 0|       8359|\n",
      "+------------+----------+----------------+---------+------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark_df_with_percentage = spark_df.withColumn(\n",
    "    'death_percentage', \n",
    "    (spark_df['total_deaths'] / spark_df['population']) * 100\n",
    ")\n",
    "spark_df_with_percentage = spark_df_with_percentage.withColumn(\n",
    "    'death_percentage',\n",
    "    F.concat(\n",
    "        # Format to 2 decimal places\n",
    "        F.format_number(spark_df_with_percentage['death_percentage'], 2), \n",
    "        # Append the percentage symbol \n",
    "        F.lit('%')  \n",
    "    )\n",
    ")\n",
    "columns_to_display = ['total_deaths', 'population', 'death_percentage', 'continent', 'total_vaccinations', 'total_cases']\n",
    "spark_df_with_percentage.select(columns_to_display).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e211538",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T08:15:23.742509Z",
     "iopub.status.busy": "2025-04-11T08:15:23.742211Z",
     "iopub.status.idle": "2025-04-11T08:15:26.004280Z",
     "shell.execute_reply": "2025-04-11T08:15:26.003344Z"
    },
    "papermill": {
     "duration": 2.272512,
     "end_time": "2025-04-11T08:15:26.006745",
     "exception": false,
     "start_time": "2025-04-11T08:15:23.734233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating the total deaths per continent:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                                              (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+\n",
      "|    continent|sum(total_deaths)|\n",
      "+-------------+-----------------+\n",
      "|       Europe|          2102483|\n",
      "|       Africa|           259117|\n",
      "|          nan|         22430618|\n",
      "|North America|          1671178|\n",
      "|South America|          1354187|\n",
      "|      Oceania|            32918|\n",
      "|         Asia|          1637249|\n",
      "+-------------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Calculating the total deaths per continent:\")\n",
    "# Group by continent and sum total death rates\n",
    "spark_df.groupby(['continent']).agg({\"total_deaths\": \"SUM\"}).show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3a92f37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T08:15:26.024148Z",
     "iopub.status.busy": "2025-04-11T08:15:26.023764Z",
     "iopub.status.idle": "2025-04-11T08:15:26.070856Z",
     "shell.execute_reply": "2025-04-11T08:15:26.070004Z"
    },
    "papermill": {
     "duration": 0.058158,
     "end_time": "2025-04-11T08:15:26.072638",
     "exception": false,
     "start_time": "2025-04-11T08:15:26.014480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.convert_total_deaths(total_deaths)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import IntegerType\n",
    "# Function definition\n",
    "def convert_total_deaths(total_deaths):\n",
    "    return total_deaths * 2\n",
    "# Here you can define any transformation you want\n",
    "# Register the UDF with Spark\n",
    "spark.udf.register(\"convert_total_deaths\", convert_total_deaths, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "943034a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T08:15:26.090007Z",
     "iopub.status.busy": "2025-04-11T08:15:26.089553Z",
     "iopub.status.idle": "2025-04-11T08:15:27.683312Z",
     "shell.execute_reply": "2025-04-11T08:15:27.682467Z"
    },
    "papermill": {
     "duration": 1.605321,
     "end_time": "2025-04-11T08:15:27.685546",
     "exception": false,
     "start_time": "2025-04-11T08:15:26.080225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                                              (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+----------------------+\n",
      "|    continent|total_deaths|converted_total_deaths|\n",
      "+-------------+------------+----------------------+\n",
      "|         Asia|        7998|                 15996|\n",
      "|          nan|      259117|                518234|\n",
      "|       Europe|        3605|                  7210|\n",
      "|       Africa|        6881|                 13762|\n",
      "|      Oceania|          34|                    68|\n",
      "|       Europe|         159|                   318|\n",
      "|       Africa|        1937|                  3874|\n",
      "|North America|          12|                    24|\n",
      "|North America|         146|                   292|\n",
      "|South America|      130663|                261326|\n",
      "|         Asia|        8777|                 17554|\n",
      "|North America|         292|                   584|\n",
      "|          nan|     1637249|               3274498|\n",
      "|      Oceania|       25236|                 50472|\n",
      "|       Europe|       22534|                 45068|\n",
      "|         Asia|       10353|                 20706|\n",
      "|North America|         849|                  1698|\n",
      "|         Asia|        1536|                  3072|\n",
      "|         Asia|       29499|                 58998|\n",
      "|North America|         593|                  1186|\n",
      "+-------------+------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    }
   ],
   "source": [
    "# Drop the existing temporary view if it exists\n",
    "spark.sql(\"DROP VIEW IF EXISTS data_v\")\n",
    "\n",
    "# Create a new temporary view\n",
    "spark_df.createTempView('data_v')\n",
    "\n",
    "# Execute the SQL query using the UDF\n",
    "spark.sql('SELECT continent, total_deaths, convert_total_deaths(total_deaths) as converted_total_deaths FROM data_v').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fde0e29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T08:15:27.703626Z",
     "iopub.status.busy": "2025-04-11T08:15:27.703232Z",
     "iopub.status.idle": "2025-04-11T08:15:27.783741Z",
     "shell.execute_reply": "2025-04-11T08:15:27.781404Z"
    },
    "papermill": {
     "duration": 0.091861,
     "end_time": "2025-04-11T08:15:27.785565",
     "exception": false,
     "start_time": "2025-04-11T08:15:27.693704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+------------+------------------+----------+\n",
      "|    continent|total_cases|total_deaths|total_vaccinations|population|\n",
      "+-------------+-----------+------------+------------------+----------+\n",
      "|         Asia|     235214|        7998|                 0|  41128772|\n",
      "|          nan|   13145380|      259117|                 0|1426736614|\n",
      "|       Europe|     335047|        3605|                 0|   2842318|\n",
      "|       Africa|     272139|        6881|                 0|  44903228|\n",
      "|      Oceania|       8359|          34|                 0|     44295|\n",
      "|       Europe|      48015|         159|                 0|     79843|\n",
      "|       Africa|     107481|        1937|                 0|  35588996|\n",
      "|North America|       3904|          12|                 0|     15877|\n",
      "|North America|       9106|         146|                 0|     93772|\n",
      "|South America|   10101218|      130663|                 0|  45510324|\n",
      "|         Asia|     452273|        8777|                 0|   2780472|\n",
      "|North America|      44224|         292|                 0|    106459|\n",
      "|          nan|  301499099|     1637249|        9104304615|4721383370|\n",
      "|      Oceania|   11861161|       25236|                 0|  26177410|\n",
      "|       Europe|    6082444|       22534|                 0|   8939617|\n",
      "|         Asia|     835757|       10353|                 0|  10358078|\n",
      "|North America|      39127|         849|                 0|    409989|\n",
      "|         Asia|     696614|        1536|                 0|   1472237|\n",
      "|         Asia|    2051348|       29499|                 0| 171186368|\n",
      "|North America|     108582|         593|                 0|    281646|\n",
      "+-------------+-----------+------------+------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT * FROM data_v').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1e74da6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T08:15:27.804356Z",
     "iopub.status.busy": "2025-04-11T08:15:27.803493Z",
     "iopub.status.idle": "2025-04-11T08:15:27.909346Z",
     "shell.execute_reply": "2025-04-11T08:15:27.907801Z"
    },
    "papermill": {
     "duration": 0.11719,
     "end_time": "2025-04-11T08:15:27.911323",
     "exception": false,
     "start_time": "2025-04-11T08:15:27.794133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying continent with total vaccinated more than 1 million:\n",
      "+-------------+\n",
      "|    continent|\n",
      "+-------------+\n",
      "|          nan|\n",
      "|North America|\n",
      "|       Europe|\n",
      "|       Europe|\n",
      "|          nan|\n",
      "|          nan|\n",
      "|          nan|\n",
      "|         Asia|\n",
      "|         Asia|\n",
      "|       Europe|\n",
      "|          nan|\n",
      "|         Asia|\n",
      "|      Oceania|\n",
      "|          nan|\n",
      "|          nan|\n",
      "|          nan|\n",
      "|          nan|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Displaying continent with total vaccinated more than 1 million:\")\n",
    "# SQL filtering\n",
    "spark.sql(\"SELECT continent FROM data_v WHERE total_vaccinations > 1000000\").show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 40.567087,
   "end_time": "2025-04-11T08:15:30.539088",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-11T08:14:49.972001",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
